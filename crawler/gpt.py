import requests
from bs4 import BeautifulSoup
import openai
from fpdf import FPDF
import urllib.parse
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import time

# ğŸ”‘ GPT API í‚¤ ì„¤ì •
openai.api_key = 'your-openai-api-key-here'

# âœ… 1. ë‰´ìŠ¤ ì œëª© & ë§í¬ í¬ë¡¤ë§
def get_naver_news_links(keyword, max_count=5):
    query = urllib.parse.quote(keyword)
    url = f"https://search.naver.com/search.naver?where=news&query={query}&sort=1&pd=1"
    headers = {"User-Agent": "Mozilla/5.0"}

    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, 'html.parser')

    articles = soup.select('a > span.sds-comps-text-type-headline1')
    news = []

    for span in articles[:max_count]:  # ìµœëŒ€ max_countê°œê¹Œì§€ë§Œ ìˆ˜ì§‘
        title = span.text.strip()
        # print("title : ", title)
        link = span.find_parent('a').get('cru') or span.find_parent('a').get('href')
        # print("link : ", link)
        if title and link:
            news.append((title, link))  # ë¦¬ìŠ¤íŠ¸ì— íŠœí”Œë¡œ ì¶”ê°€
    return news


# âœ… 2. ë³¸ë¬¸ í¬ë¡¤ë§ (ì‚¬ì´íŠ¸ë³„ êµ¬ì¡°ê°€ ë‹¬ë¼ ë‹¨ìˆœíˆ <p> íƒœê·¸ ì¶”ì¶œ)
def get_article_content(url):
    try:
        # ë¸Œë¼ìš°ì € ì—´ê¸°
        options = webdriver.ChromeOptions()
        options.add_argument("--headless")  # ì°½ ì•ˆ ë„ìš°ëŠ” ëª¨ë“œ
        options.add_argument("--no-sandbox")
        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

        # URL ì ‘ì†
        driver.get(url)
        time.sleep(3)  # JS ë¡œë”© ê¸°ë‹¤ë¦¬ê¸°

        # HTML íŒŒì‹±
        soup = BeautifulSoup(driver.page_source, "html.parser")
        paragraphs = soup.find_all("p")

        # ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶œë ¥
        for p in paragraphs:
            print(p.get_text(strip=True))

        driver.quit()
    except:
        return ""

# âœ… 3. GPTì—ê²Œ ìš”ì•½ ìš”ì²­
def summarize_with_gpt(news_texts):
    combined = "\n\n".join(news_texts)
    prompt = f"""ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ ë‚´ìš©ì„ ì¢…í•©í•´ì„œ í•œê¸€ë¡œ ìš”ì•½í•´ì¤˜. ì¤‘ìš”í•œ í‚¤ì›Œë“œì™€ íë¦„ ì¤‘ì‹¬ìœ¼ë¡œ ì •ë¦¬í•´ì¤˜:\n\n{combined}"""

    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )

    return response['choices'][0]['message']['content'].strip()

# âœ… 4. PDF ì €ì¥
def save_to_pdf(text, filename="ë‰´ìŠ¤_ìš”ì•½.pdf"):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)

    for line in text.split('\n'):
        pdf.multi_cell(0, 10, line)
    pdf.output(filename)
    print(f"âœ… PDFë¡œ ì €ì¥ ì™„ë£Œ: {filename}")

# âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
def full_pipeline(keyword):
    print(f"ğŸ” '{keyword}' í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
    news_items = get_naver_news_links(keyword)

    news_contents = []
    for title, link in news_items:
        print(f"ğŸ“° {title} -> {link}")
        content = get_article_content(link)
        if content:
            news_contents.append(content)
        time.sleep(1)  # ë„¤ì´ë²„/ì–¸ë¡ ì‚¬ ì„œë²„ì— ë¶€ë‹´ ì¤„ì´ê¸°

    if not news_contents:
        print("âŒ ë‰´ìŠ¤ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆì–´ìš”.")
        return

    print("\nğŸ¤– GPTì—ê²Œ ìš”ì•½ ìš”ì²­ ì¤‘...")
    summary = summarize_with_gpt(news_contents)
    print("\nğŸ“ ìš”ì•½ ê²°ê³¼:\n", summary)

    print("\nğŸ“„ PDFë¡œ ì €ì¥ ì¤‘...")
    save_to_pdf(summary)





# ğŸš€ ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    keyword = input("ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
    full_pipeline(keyword)
